# LLM Prompt Recovery

## Overview

```
This project aims to improve the quality of text prompts using various language models,
including Mistral 7B, Mixtral, Gemma, Llama, and Phi. The notebook demonstrates the process of
loading models, preprocessing text, generating improved prompts, and evaluating the
performance.
```
## Structure

```
The project is organized into several key sections:
```
1. **Setup and Configuration** : Importing necessary libraries and configuring settings.
2. **Data Loading and Preprocessing** : Loading datasets and preparing text for model input.
3. **Model Loading** : Loading pre-trained language models for prompt improvement.
4. **Prompt Improvement** : Using models to generate improved text prompts.
5. **Evaluation** : Assessing the quality of the generated prompts.

## Installation

```
To run this project, you need to have Python and several libraries installed. You can install the
required libraries using the following command:
```
```
pip install torch pandas transformers
```

## Notebooks and Scripts

```
llm-prompt-recovery.ipynb : Main notebook containing the entire workflow.
models : Directory containing model-related scripts and configurations.
```
## Data

```
Prompt Recovery Compettion Data = https://www.kaggle.com/competitions/llm-prompt-recovery
```
## Contributing

```
Contributions are welcome! Please create a pull request or open an issue to discuss your ideas.
```

