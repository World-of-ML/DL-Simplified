{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"./../Dataset/newData.csv\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# Drop rows with missing text values\n",
    "data = data.dropna(subset=['Transformer_text'])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize and pad the text data\n",
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_data['Transformer_text'])\n",
    "\n",
    "# Convert text data to sequences and pad them\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['Transformer_text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['Transformer_text'])\n",
    "\n",
    "max_length = 100\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_data['Label'])\n",
    "\n",
    "test_labels = label_encoder.transform(test_data['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16  # Adjust based on your preference\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_length))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "130/130 [==============================] - 10s 45ms/step - loss: 0.4233 - accuracy: 0.8656 - val_loss: 0.3586 - val_accuracy: 0.8858\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.3875 - accuracy: 0.8705 - val_loss: 0.3607 - val_accuracy: 0.8858\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.3881 - accuracy: 0.8705 - val_loss: 0.3556 - val_accuracy: 0.8858\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.3868 - accuracy: 0.8705 - val_loss: 0.3559 - val_accuracy: 0.8858\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.3873 - accuracy: 0.8705 - val_loss: 0.3584 - val_accuracy: 0.8858\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.3875 - accuracy: 0.8705 - val_loss: 0.3623 - val_accuracy: 0.8858\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.3862 - accuracy: 0.8705 - val_loss: 0.3568 - val_accuracy: 0.8858\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.3862 - accuracy: 0.8705 - val_loss: 0.3610 - val_accuracy: 0.8858\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.3873 - accuracy: 0.8705 - val_loss: 0.3575 - val_accuracy: 0.8858\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.3862 - accuracy: 0.8705 - val_loss: 0.3565 - val_accuracy: 0.8858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bc814a6150>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10  # Adjust based on your training preference\n",
    "model.fit(train_padded, train_labels, epochs=epochs, validation_data=(test_padded, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 12ms/step - loss: 0.3565 - accuracy: 0.8858\n",
      "Test Loss: 0.3565\n",
      "Test Accuracy: 0.8858\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_padded, test_labels)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_length))\n",
    "model2.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model2.add(Bidirectional(LSTM(64)))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "130/130 [==============================] - 21s 85ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0987 - val_accuracy: 0.9787\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1223 - val_accuracy: 0.9768\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1234 - val_accuracy: 0.9797\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 6.4813e-05 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9787\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 3.2407e-05 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bc94639210>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model with Adam optimizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model2.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 5\n",
    "model2.fit(train_padded, train_labels, epochs=epochs, validation_data=(test_padded, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 21ms/step - loss: 0.1413 - accuracy: 0.9797\n",
      "Test Loss: 0.1413\n",
      "Test Accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model2.evaluate(test_padded, test_labels)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STREAMLIT GUI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# # Load the trained model\n",
    "# model = tf.keras.models.load_model('path/to/your/trained/model')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(['your', 'list', 'of', 'common', 'words'])\n",
    "\n",
    "# Define the maximum sequence length (adjust based on your model)\n",
    "max_length = 100\n",
    "\n",
    "# Streamlit App\n",
    "def main():\n",
    "    st.title(\"SPAM vs HAM Email Classification\")\n",
    "\n",
    "    # User input\n",
    "    user_input = st.text_area(\"Enter the email text:\")\n",
    "\n",
    "    if st.button(\"Predict\"):\n",
    "        # Tokenize and pad the input text\n",
    "        input_sequence = tokenizer.texts_to_sequences([user_input])\n",
    "        padded_input = pad_sequences(input_sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "        # Make the prediction\n",
    "        prediction = model2.predict(padded_input)\n",
    "\n",
    "        # Display the result\n",
    "        if prediction[0][0] > 0.5:\n",
    "            st.success(\"Prediction: HAM (Legitimate Email)\")\n",
    "        else:\n",
    "            st.error(\"Prediction: SPAM\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
