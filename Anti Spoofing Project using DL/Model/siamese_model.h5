import os
import cv2
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Lambda, Input
from tensorflow.keras.optimizers import Adam

print("model file called ")
# Function to load videos from a folder
def load_videos_from_folder(folder):
    videos = []
    if os.path.exists(folder):
        for filename in os.listdir(folder):
            vid_path = os.path.join(folder, filename)
            if os.path.isfile(vid_path):
                vid = cv2.VideoCapture(vid_path)
                while True:
                    ret, frame = vid.read()
                    if not ret:
                        break
                    frame = cv2.resize(frame, (image_width, image_height))  # Resize frame to desired dimensions
                    videos.append(frame)
                vid.release()
    return videos

# Function to load images from a folder
def load_images_from_folder(folder):
    images = []
    if os.path.exists(folder):
        for filename in os.listdir(folder):
            img_path = os.path.join(folder, filename)
            if os.path.isfile(img_path):
                img = load_img(img_path, target_size=(image_height, image_width))
                img_array = img_to_array(img)
                images.append(img_array)
    return images

# Set the file paths for your datasets
dataset_folder = "/kaggle/input/anti-spoofing"
cut_out_printouts_folder = os.path.join(dataset_folder, "cut-out printouts")
live_selfie_folder = os.path.join(dataset_folder, "live_selfie")
live_video_folder = os.path.join(dataset_folder, "live_video")
printouts_folder = os.path.join(dataset_folder, "printouts")
replay_folder = os.path.join(dataset_folder, "replay")

# Set the desired image dimensions
image_height = 224
image_width = 224

# Load the data
cut_out_printouts = load_videos_from_folder(cut_out_printouts_folder)
live_selfie = load_images_from_folder(live_selfie_folder)
live_video = load_videos_from_folder(live_video_folder)
printouts = load_videos_from_folder(printouts_folder)
replay = load_videos_from_folder(replay_folder)

# Combine the data and labels
X = np.array(cut_out_printouts + live_selfie + live_video + printouts + replay)
y = np.array([0] * len(cut_out_printouts) + [1] * len(live_selfie) + [2] * len(live_video) + [3] * len(
    printouts) + [4] * len(replay))

# Split the data into training, validation, and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)

# Normalize the data
X_train = X_train / 255.0
X_val = X_val / 255.0

# Convert labels to one-hot encoded format
num_classes = 5
y_train_one_hot = to_categorical(y_train, num_classes)
y_val_one_hot = to_categorical(y_val, num_classes)

# Build and train the CNN model
cnn_model = Sequential()
cnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(image_height, image_width, 3)))
cnn_model.add(MaxPooling2D(pool_size=(2, 2)))
cnn_model.add(Flatten())
cnn_model.add(Dense(num_classes, activation='softmax'))

cnn_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])
cnn_history = cnn_model.fit(X_train, y_train_one_hot, batch_size=32, epochs=10, validation_data=(X_val, y_val_one_hot))

# Print the accuracy
_, train_accuracy = cnn_model.evaluate(X_train, y_train_one_hot, verbose=0)
_, val_accuracy = cnn_model.evaluate(X_val, y_val_one_hot, verbose=0)

print("Training Accuracy: {:.2f}%".format(train_accuracy * 100))
print("Validation Accuracy: {:.2f}%".format(val_accuracy * 100))

# Plot the learning curve
plt.figure(figsize=(12, 6))
plt.plot(cnn_history.history['accuracy'], label='Training Accuracy')
plt.plot(cnn_history.history['val_accuracy'], label='Validation Accuracy')
plt.title('CNN Model - Learning Curve')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.show()

# Load and preprocess video frames
def load_and_preprocess_video(file_path):
    # Check if the file exists
    if not os.path.exists(file_path):
        print("File not found:", file_path)
        return None

    # Initialize video capture
    cap = cv2.VideoCapture(file_path)

    frames = []
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, (image_width, image_height))
        frames.append(frame)

    # Release the video capture object
    cap.release()

    return np.array(frames)

# Function to predict the label of a video
def predict_video_label(file_path):
    # Load and preprocess the video frames
    video_frames = load_and_preprocess_video(file_path)

    # Check if the video frames are loaded successfully
    if video_frames is None:
        print("Unable to load video frames.")
        return None

    # Perform the prediction
    predictions = cnn_model.predict(video_frames)
    average_prediction = np.mean(predictions, axis=0)
    predicted_class = np.argmax(average_prediction)
    confidence = average_prediction[predicted_class]

    return predicted_class, confidence

# Test the prediction function on a sample video
sample_video_path = "/kaggle/input/anti-spoofing/replay/0058.MOV"
predicted_label, confidence = predict_video_label(sample_video_path)
print("Predicted Label:", predicted_label)
print("Confidence:", confidence)
