{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Sudoku Solver Using CNN, RNN and GAN Model**"
      ],
      "metadata": {
        "id": "j_gCgQp1BCzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and Data Preprocessing"
      ],
      "metadata": {
        "id": "ZCK9knTqDRTj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IbbOLWdf95X_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_and_preprocess_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    X = data['puzzle'].apply(lambda x: np.array([int(i) for i in x]).reshape((9, 9, 1)))\n",
        "    y = data['solution'].apply(lambda x: np.array([int(i) for i in x]).reshape((9, 9, 1)))\n",
        "\n",
        "    X = np.stack(X.values)\n",
        "    y = np.stack(y.values)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "file_path = \"sudoku_dataset.csv\"\n",
        "X_train, X_test, y_train, y_test = load_and_preprocess_data(file_path)\n"
      ],
      "metadata": {
        "id": "6uXgr-bE9V7H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the CNN model"
      ],
      "metadata": {
        "id": "HT-_qihRCj6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape\n",
        "\n",
        "def create_cnn_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional layers\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(9, 9, 1)))\n",
        "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(81, activation='relu'))\n",
        "    model.add(Dense(81, activation='softmax'))\n",
        "    model.add(Reshape((9, 9, 1)))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_cnn_model()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct71U0am9Y7t",
        "outputId": "5206d145-6c40-4027-c53b-e16884b137c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 9, 9, 64)          640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 5, 5, 64)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 5, 5, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 3, 3, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 81)                93393     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 81)                6642      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 9, 9, 1)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 174531 (681.76 KB)\n",
            "Trainable params: 174531 (681.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the CNN model"
      ],
      "metadata": {
        "id": "c8HUfiKnCnue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_and_preprocess_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    X = data['puzzle'].apply(lambda x: np.array([int(i) for i in x]).reshape((9, 9, 1)))\n",
        "    y = data['solution'].apply(lambda x: np.array([int(i) - 1 for i in x]).reshape((9, 9, 1)))  # Adjust labels\n",
        "\n",
        "    X = np.stack(X.values)\n",
        "    y = np.stack(y.values)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "file_path = \"sudoku_dataset.csv\"\n",
        "X_train, X_test, y_train, y_test = load_and_preprocess_data(file_path)\n"
      ],
      "metadata": {
        "id": "3vN8rxkJ-jel"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JlL_X1CsCyB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKUFk-qs-A4P",
        "outputId": "d7bce593-32e2-4cb5-ca64-9ba455d791e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 2s 42ms/step - loss: 1.4585 - accuracy: 0.7627 - val_loss: 0.8336 - val_accuracy: 0.8030\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.9360 - accuracy: 0.7967 - val_loss: 0.8336 - val_accuracy: 0.8030\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 1s 34ms/step - loss: 0.9358 - accuracy: 0.7967 - val_loss: 0.8336 - val_accuracy: 0.8030\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.9358 - accuracy: 0.7967 - val_loss: 0.8336 - val_accuracy: 0.8030\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.9358 - accuracy: 0.7967 - val_loss: 0.8336 - val_accuracy: 0.8030\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.9358 - accuracy: 0.7967 - val_loss: 0.8336 - val_accuracy: 0.8030\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 0.9358 - accuracy: 0.7967 - val_loss: 0.8336 - val_accuracy: 0.8030\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 1s 33ms/step - loss: 0.9358 - accuracy: 0.7967 - val_loss: 0.8336 - val_accuracy: 0.8030\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 0.9358 - accuracy: 0.7967 - val_loss: 0.8336 - val_accuracy: 0.8030\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 1s 34ms/step - loss: 0.9358 - accuracy: 0.7967 - val_loss: 0.8336 - val_accuracy: 0.8030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and save model"
      ],
      "metadata": {
        "id": "XeyxQ_HjC4X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "model.save(\"sudoku_cnn_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4nCY_o9_Es2",
        "outputId": "5445458c-1ed2-4661-d0b2-cb8dcbd1feb6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 11ms/step - loss: 0.8336 - accuracy: 0.8030\n",
            "Test accuracy: 80.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the Dataset"
      ],
      "metadata": {
        "id": "PYHVoZiGCVTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_kcURXN_snp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the input data\n",
        "X_train_rnn = X_train.reshape(-1, 81, 1)\n",
        "X_test_rnn = X_test.reshape(-1, 81, 1)\n",
        "\n",
        "# Reshape the target data\n",
        "y_train_rnn = y_train.reshape(-1, 81)\n",
        "y_test_rnn = y_test.reshape(-1, 81)\n"
      ],
      "metadata": {
        "id": "t1T7giwH_skP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the RNN model"
      ],
      "metadata": {
        "id": "1f4K5RXuCQgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, TimeDistributed\n",
        "\n",
        "def create_rnn_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # RNN layer\n",
        "    model.add(SimpleRNN(128, input_shape=(81, 1), return_sequences=True))\n",
        "\n",
        "    # Fully connected layer\n",
        "    model.add(TimeDistributed(Dense(9, activation='softmax')))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model_rnn = create_rnn_model()\n",
        "model_rnn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_eABFOj_sgI",
        "outputId": "54597097-838a-44ce-ce23-e84b5b746692"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 81, 128)           16640     \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 81, 9)             1161      \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17801 (69.54 KB)\n",
            "Trainable params: 17801 (69.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the RNN model"
      ],
      "metadata": {
        "id": "bIMJh46dCJEK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kcQfZ88hALK4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_rnn = model_rnn.fit(X_train_rnn, y_train_rnn, epochs=10, validation_data=(X_test_rnn, y_test_rnn))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqY-EI_l_v9H",
        "outputId": "570b1954-bc5e-4e2c-a527-2b6ad9836efc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 2s 45ms/step - loss: 2.1415 - accuracy: 0.1833 - val_loss: 2.0071 - val_accuracy: 0.2494\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.9373 - accuracy: 0.2871 - val_loss: 1.8315 - val_accuracy: 0.3372\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 1.6807 - accuracy: 0.4121 - val_loss: 1.4423 - val_accuracy: 0.5185\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.2448 - accuracy: 0.6046 - val_loss: 0.9796 - val_accuracy: 0.7107\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.8109 - accuracy: 0.8112 - val_loss: 0.5866 - val_accuracy: 0.9219\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 1s 36ms/step - loss: 0.5116 - accuracy: 0.9453 - val_loss: 0.3821 - val_accuracy: 0.9704\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 0.3838 - accuracy: 0.9615 - val_loss: 0.3058 - val_accuracy: 0.9710\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.3364 - accuracy: 0.9615 - val_loss: 0.2736 - val_accuracy: 0.9710\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.3131 - accuracy: 0.9615 - val_loss: 0.2563 - val_accuracy: 0.9710\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.2984 - accuracy: 0.9615 - val_loss: 0.2435 - val_accuracy: 0.9710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate and save the RNN model"
      ],
      "metadata": {
        "id": "uDgBlBHkCEuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_rnn, accuracy_rnn = model_rnn.evaluate(X_test_rnn, y_test_rnn)\n",
        "print(f'Test accuracy (RNN): {accuracy_rnn * 100:.2f}%')\n",
        "\n",
        "model_rnn.save(\"sudoku_rnn_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmXgIgYG_3rf",
        "outputId": "09c0cc41-2240-48ad-ad6e-c782046232ec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2435 - accuracy: 0.9710\n",
            "Test accuracy (RNN): 97.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yTnUhHK4_3oJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAN MODEL"
      ],
      "metadata": {
        "id": "WykzYq6YBnfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the *GAN* Model"
      ],
      "metadata": {
        "id": "twpcAvnZBtBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, Input, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Generator model\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=81))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(81, activation='tanh'))\n",
        "    model.add(Reshape((9, 9, 1)))\n",
        "    return model\n",
        "\n",
        "# Discriminator model\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(9, 9, 1)))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Combine generator and discriminator into GAN\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=(81,))\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x)\n",
        "    gan = Model(gan_input, gan_output)\n",
        "    return gan\n",
        "\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "gan = build_gan(generator, discriminator)\n",
        "gan.compile(optimizer=Adam(), loss='binary_crossentropy')\n",
        "\n",
        "generator.summary()\n",
        "discriminator.summary()\n",
        "gan.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PvBidOA_3lA",
        "outputId": "8d33db17-cf57-418e-9dc1-93e87e1a4669"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 128)               10496     \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 81)                10449     \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 9, 9, 1)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20945 (81.82 KB)\n",
            "Trainable params: 20945 (81.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 81)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               10496     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10625 (41.50 KB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 10625 (41.50 KB)\n",
            "_________________________________________________________________\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 81)]              0         \n",
            "                                                                 \n",
            " sequential_3 (Sequential)   (None, 9, 9, 1)           20945     \n",
            "                                                                 \n",
            " sequential_4 (Sequential)   (None, 1)                 10625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31570 (123.32 KB)\n",
            "Trainable params: 20945 (81.82 KB)\n",
            "Non-trainable params: 10625 (41.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train The GAN model"
      ],
      "metadata": {
        "id": "TbT7ELskB95w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def train_gan(generator, discriminator, gan, epochs, batch_size, X_train):\n",
        "    for epoch in range(epochs):\n",
        "        # Train discriminator\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        real_puzzles = X_train[idx]\n",
        "        real_labels = np.ones((batch_size, 1))\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, 81))\n",
        "        generated_puzzles = generator.predict(noise)\n",
        "        fake_labels = np.zeros((batch_size, 1))\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_puzzles, real_labels)\n",
        "        d_loss_fake = discriminator.train_on_batch(generated_puzzles, fake_labels)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Train generator\n",
        "        noise = np.random.normal(0, 1, (batch_size, 81))\n",
        "        valid_labels = np.ones((batch_size, 1))\n",
        "        g_loss = gan.train_on_batch(noise, valid_labels)\n",
        "\n",
        "        print(f\"{epoch + 1}/{epochs}, D Loss: {d_loss[0]}, D Acc: {d_loss[1] * 100}, G Loss: {g_loss}\")\n",
        "\n",
        "train_gan(generator, discriminator, gan, epochs=300, batch_size=32, X_train=X_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct2XXw6m_3hZ",
        "outputId": "98d754bc-7896-448c-f134-5dfa32d11a51"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/300, D Loss: 1.6983628273010254, D Acc: 51.5625, G Loss: 0.8388799428939819\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2/300, D Loss: 0.7352100610733032, D Acc: 57.8125, G Loss: 0.77715003490448\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/300, D Loss: 0.45148687064647675, D Acc: 75.0, G Loss: 0.6669942736625671\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4/300, D Loss: 0.4855080246925354, D Acc: 67.1875, G Loss: 0.6806495189666748\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5/300, D Loss: 0.4292052686214447, D Acc: 68.75, G Loss: 0.5664829015731812\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/300, D Loss: 0.4495936706662178, D Acc: 59.375, G Loss: 0.49914705753326416\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7/300, D Loss: 0.5275618591695093, D Acc: 54.6875, G Loss: 0.5535911321640015\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8/300, D Loss: 0.5218309173360467, D Acc: 56.25, G Loss: 0.45530271530151367\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9/300, D Loss: 0.5944717936217785, D Acc: 54.6875, G Loss: 0.3975256681442261\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "10/300, D Loss: 0.6049218960833969, D Acc: 50.0, G Loss: 0.4140048623085022\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "11/300, D Loss: 0.6622674963437021, D Acc: 50.0, G Loss: 0.3526414632797241\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "12/300, D Loss: 0.6982959849119652, D Acc: 50.0, G Loss: 0.41805416345596313\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "13/300, D Loss: 0.6586476699449122, D Acc: 51.5625, G Loss: 0.39000123739242554\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "14/300, D Loss: 0.7196095637045801, D Acc: 51.5625, G Loss: 0.31798693537712097\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "15/300, D Loss: 0.6928852172859479, D Acc: 50.0, G Loss: 0.3483944535255432\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "16/300, D Loss: 0.7694995465717511, D Acc: 51.5625, G Loss: 0.31470367312431335\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "17/300, D Loss: 0.6707131282310002, D Acc: 50.0, G Loss: 0.35261788964271545\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "18/300, D Loss: 0.7253535177296726, D Acc: 50.0, G Loss: 0.3623581826686859\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "19/300, D Loss: 0.7287596806127112, D Acc: 51.5625, G Loss: 0.34871727228164673\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "20/300, D Loss: 0.691138592606876, D Acc: 50.0, G Loss: 0.35535287857055664\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "21/300, D Loss: 0.6866703921696171, D Acc: 50.0, G Loss: 0.40375569462776184\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "22/300, D Loss: 0.5773664837470278, D Acc: 57.8125, G Loss: 0.37353360652923584\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "23/300, D Loss: 0.6193019416532479, D Acc: 51.5625, G Loss: 0.4169309139251709\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "24/300, D Loss: 0.5246776122075971, D Acc: 50.0, G Loss: 0.46400582790374756\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "25/300, D Loss: 0.5815237088827416, D Acc: 53.125, G Loss: 0.4725632071495056\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "26/300, D Loss: 0.5156336444197223, D Acc: 54.6875, G Loss: 0.5390726327896118\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "27/300, D Loss: 0.45909182459581643, D Acc: 60.9375, G Loss: 0.617462694644928\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "28/300, D Loss: 0.46611709147691727, D Acc: 54.6875, G Loss: 0.6469601392745972\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "29/300, D Loss: 0.36883911374025047, D Acc: 70.3125, G Loss: 0.7349033951759338\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "30/300, D Loss: 0.34227685956284404, D Acc: 82.8125, G Loss: 0.6600852608680725\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "31/300, D Loss: 0.3304934096522629, D Acc: 76.5625, G Loss: 0.8675744533538818\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "32/300, D Loss: 0.3075071293860674, D Acc: 84.375, G Loss: 0.8786330223083496\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "33/300, D Loss: 0.28872784599661827, D Acc: 93.75, G Loss: 0.9808696508407593\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "34/300, D Loss: 0.27166576124727726, D Acc: 90.625, G Loss: 1.1144771575927734\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "35/300, D Loss: 0.23650016263127327, D Acc: 98.4375, G Loss: 1.1099157333374023\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "36/300, D Loss: 0.24343538098037243, D Acc: 96.875, G Loss: 1.113823413848877\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "37/300, D Loss: 0.23739782348275185, D Acc: 100.0, G Loss: 1.242695927619934\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "38/300, D Loss: 0.24199169501662254, D Acc: 96.875, G Loss: 1.2300629615783691\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "39/300, D Loss: 0.23398857563734055, D Acc: 96.875, G Loss: 1.3742823600769043\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "40/300, D Loss: 0.20941197872161865, D Acc: 98.4375, G Loss: 1.172267198562622\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "41/300, D Loss: 0.23993568867444992, D Acc: 100.0, G Loss: 1.1855100393295288\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "42/300, D Loss: 0.24287457764148712, D Acc: 95.3125, G Loss: 1.2659759521484375\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "43/300, D Loss: 0.25248189456760883, D Acc: 96.875, G Loss: 1.1547132730484009\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "44/300, D Loss: 0.26603880897164345, D Acc: 95.3125, G Loss: 1.2096171379089355\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "45/300, D Loss: 0.2242293767631054, D Acc: 98.4375, G Loss: 1.251335859298706\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "46/300, D Loss: 0.25357985869050026, D Acc: 95.3125, G Loss: 1.2467002868652344\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "47/300, D Loss: 0.22930724173784256, D Acc: 93.75, G Loss: 1.0541821718215942\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "48/300, D Loss: 0.2476759608834982, D Acc: 95.3125, G Loss: 1.1461595296859741\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "49/300, D Loss: 0.23942524753510952, D Acc: 95.3125, G Loss: 1.0437166690826416\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "50/300, D Loss: 0.304033737629652, D Acc: 89.0625, G Loss: 0.9810782670974731\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "51/300, D Loss: 0.2987062484025955, D Acc: 89.0625, G Loss: 0.9917836785316467\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "52/300, D Loss: 0.33677149564027786, D Acc: 89.0625, G Loss: 1.0418269634246826\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "53/300, D Loss: 0.2974735349416733, D Acc: 93.75, G Loss: 1.0188945531845093\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "54/300, D Loss: 0.30169362109154463, D Acc: 85.9375, G Loss: 1.0695630311965942\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "55/300, D Loss: 0.29324520751833916, D Acc: 92.1875, G Loss: 1.0541964769363403\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "56/300, D Loss: 0.379189096391201, D Acc: 87.5, G Loss: 0.8752045631408691\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "57/300, D Loss: 0.3211117163300514, D Acc: 87.5, G Loss: 1.0009446144104004\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "58/300, D Loss: 0.32181890681385994, D Acc: 89.0625, G Loss: 1.0338231325149536\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "59/300, D Loss: 0.3038793057203293, D Acc: 89.0625, G Loss: 1.0609650611877441\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "60/300, D Loss: 0.26583388075232506, D Acc: 95.3125, G Loss: 1.0870695114135742\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "61/300, D Loss: 0.2347879707813263, D Acc: 98.4375, G Loss: 1.2413535118103027\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "62/300, D Loss: 0.29025421291589737, D Acc: 95.3125, G Loss: 1.1649518013000488\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "63/300, D Loss: 0.2849067151546478, D Acc: 92.1875, G Loss: 1.1761738061904907\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "64/300, D Loss: 0.255884550511837, D Acc: 95.3125, G Loss: 1.3795716762542725\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "65/300, D Loss: 0.23209425061941147, D Acc: 96.875, G Loss: 1.2471317052841187\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "66/300, D Loss: 0.2427729219198227, D Acc: 95.3125, G Loss: 1.4293978214263916\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "67/300, D Loss: 0.27101265639066696, D Acc: 96.875, G Loss: 1.2033053636550903\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "68/300, D Loss: 0.27752090990543365, D Acc: 95.3125, G Loss: 1.2749159336090088\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "69/300, D Loss: 0.26638396829366684, D Acc: 95.3125, G Loss: 1.2180107831954956\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "70/300, D Loss: 0.2524896338582039, D Acc: 93.75, G Loss: 1.256223440170288\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "71/300, D Loss: 0.3269952982664108, D Acc: 93.75, G Loss: 1.2353514432907104\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "72/300, D Loss: 0.2107973713427782, D Acc: 96.875, G Loss: 1.3282146453857422\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "73/300, D Loss: 0.1909522907808423, D Acc: 98.4375, G Loss: 1.425438642501831\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "74/300, D Loss: 0.1805403269827366, D Acc: 98.4375, G Loss: 1.2650730609893799\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "75/300, D Loss: 0.1853626649826765, D Acc: 98.4375, G Loss: 1.3689765930175781\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "76/300, D Loss: 0.17769497307017446, D Acc: 100.0, G Loss: 1.4469358921051025\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "77/300, D Loss: 0.18913715332746506, D Acc: 98.4375, G Loss: 1.552248239517212\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "78/300, D Loss: 0.22257595136761665, D Acc: 95.3125, G Loss: 1.693932294845581\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "79/300, D Loss: 0.22887106239795685, D Acc: 96.875, G Loss: 1.5517469644546509\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "80/300, D Loss: 0.17276351526379585, D Acc: 100.0, G Loss: 1.4672893285751343\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "81/300, D Loss: 0.20354051887989044, D Acc: 93.75, G Loss: 1.6225448846817017\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "82/300, D Loss: 0.2921915426850319, D Acc: 92.1875, G Loss: 1.5686639547348022\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "83/300, D Loss: 0.2526140660047531, D Acc: 92.1875, G Loss: 1.4985239505767822\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "84/300, D Loss: 0.20022022118791938, D Acc: 96.875, G Loss: 1.3166556358337402\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "85/300, D Loss: 0.2527061775326729, D Acc: 93.75, G Loss: 1.4690260887145996\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "86/300, D Loss: 0.3176572322845459, D Acc: 87.5, G Loss: 1.099890947341919\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "87/300, D Loss: 0.3557155355811119, D Acc: 85.9375, G Loss: 1.3249261379241943\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "88/300, D Loss: 0.2225402258336544, D Acc: 93.75, G Loss: 1.233041524887085\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "89/300, D Loss: 0.2576163155026734, D Acc: 89.0625, G Loss: 1.3923327922821045\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "90/300, D Loss: 0.21385220531374216, D Acc: 93.75, G Loss: 1.4771504402160645\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "91/300, D Loss: 0.268436960875988, D Acc: 87.5, G Loss: 1.6661189794540405\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "92/300, D Loss: 0.22887633182108402, D Acc: 92.1875, G Loss: 1.705112338066101\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "93/300, D Loss: 0.21281777694821358, D Acc: 92.1875, G Loss: 1.4459396600723267\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "94/300, D Loss: 0.1889477949589491, D Acc: 96.875, G Loss: 1.5923216342926025\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "95/300, D Loss: 0.25244560837745667, D Acc: 92.1875, G Loss: 1.5682218074798584\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "96/300, D Loss: 0.16791755706071854, D Acc: 96.875, G Loss: 1.494059681892395\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "97/300, D Loss: 0.29363778978586197, D Acc: 93.75, G Loss: 1.3793036937713623\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "98/300, D Loss: 0.21796249225735664, D Acc: 95.3125, G Loss: 1.3198378086090088\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "99/300, D Loss: 0.2774408273398876, D Acc: 89.0625, G Loss: 1.4036929607391357\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "100/300, D Loss: 0.2732117995619774, D Acc: 90.625, G Loss: 1.3303947448730469\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "101/300, D Loss: 0.21341604460030794, D Acc: 93.75, G Loss: 1.3074984550476074\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "102/300, D Loss: 0.25112298503518105, D Acc: 93.75, G Loss: 1.4056472778320312\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "103/300, D Loss: 0.23075809702277184, D Acc: 90.625, G Loss: 1.4484822750091553\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "104/300, D Loss: 0.24152575433254242, D Acc: 90.625, G Loss: 1.4034181833267212\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "105/300, D Loss: 0.23440157994627953, D Acc: 95.3125, G Loss: 1.488136649131775\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "106/300, D Loss: 0.3159109503030777, D Acc: 89.0625, G Loss: 1.536409854888916\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "107/300, D Loss: 0.20768714509904385, D Acc: 93.75, G Loss: 1.4081840515136719\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "108/300, D Loss: 0.2564331963658333, D Acc: 92.1875, G Loss: 1.588666319847107\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "109/300, D Loss: 0.21720874309539795, D Acc: 90.625, G Loss: 1.4890968799591064\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "110/300, D Loss: 0.2360234335064888, D Acc: 93.75, G Loss: 1.4574224948883057\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "111/300, D Loss: 0.1854565478861332, D Acc: 93.75, G Loss: 1.7479000091552734\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "112/300, D Loss: 0.26275085657835007, D Acc: 93.75, G Loss: 1.6334731578826904\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "113/300, D Loss: 0.18919463269412518, D Acc: 93.75, G Loss: 1.5237736701965332\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "114/300, D Loss: 0.18640479445457458, D Acc: 96.875, G Loss: 1.503614902496338\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "115/300, D Loss: 0.1914785597473383, D Acc: 95.3125, G Loss: 1.628110408782959\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "116/300, D Loss: 0.1720263957977295, D Acc: 96.875, G Loss: 1.7485337257385254\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "117/300, D Loss: 0.1944713518023491, D Acc: 95.3125, G Loss: 1.6618989706039429\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "118/300, D Loss: 0.14394215866923332, D Acc: 100.0, G Loss: 1.8039603233337402\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "119/300, D Loss: 0.2279757708311081, D Acc: 92.1875, G Loss: 1.807948112487793\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "120/300, D Loss: 0.16538128443062305, D Acc: 96.875, G Loss: 1.6901178359985352\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "121/300, D Loss: 0.18920914828777313, D Acc: 96.875, G Loss: 1.6119886636734009\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "122/300, D Loss: 0.12503001652657986, D Acc: 98.4375, G Loss: 1.6237311363220215\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "123/300, D Loss: 0.15117726475000381, D Acc: 98.4375, G Loss: 1.9028561115264893\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "124/300, D Loss: 0.24795112013816833, D Acc: 96.875, G Loss: 1.8004764318466187\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "125/300, D Loss: 0.1366057638078928, D Acc: 98.4375, G Loss: 2.075869083404541\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "126/300, D Loss: 0.17716555297374725, D Acc: 92.1875, G Loss: 2.0438122749328613\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "127/300, D Loss: 0.22585001587867737, D Acc: 93.75, G Loss: 1.9401975870132446\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/300, D Loss: 0.20700450241565704, D Acc: 95.3125, G Loss: 1.7637583017349243\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "129/300, D Loss: 0.13369737938046455, D Acc: 98.4375, G Loss: 1.9549894332885742\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "130/300, D Loss: 0.1800847314298153, D Acc: 95.3125, G Loss: 2.0775458812713623\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "131/300, D Loss: 0.16689490899443626, D Acc: 96.875, G Loss: 1.7631574869155884\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "132/300, D Loss: 0.09461850905790925, D Acc: 98.4375, G Loss: 1.937809705734253\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "133/300, D Loss: 0.16150282323360443, D Acc: 93.75, G Loss: 1.9188897609710693\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "134/300, D Loss: 0.10686302790418267, D Acc: 98.4375, G Loss: 2.159571886062622\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "135/300, D Loss: 0.12558704987168312, D Acc: 96.875, G Loss: 2.1385998725891113\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "136/300, D Loss: 0.13715875893831253, D Acc: 95.3125, G Loss: 2.193779468536377\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "137/300, D Loss: 0.1730513870716095, D Acc: 93.75, G Loss: 2.281527280807495\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "138/300, D Loss: 0.17352987080812454, D Acc: 95.3125, G Loss: 2.4242095947265625\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "139/300, D Loss: 0.2493111491203308, D Acc: 93.75, G Loss: 1.9947400093078613\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "140/300, D Loss: 0.16717194579541683, D Acc: 93.75, G Loss: 2.010803699493408\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "141/300, D Loss: 0.16540705412626266, D Acc: 95.3125, G Loss: 1.6510258913040161\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "142/300, D Loss: 0.18783455714583397, D Acc: 92.1875, G Loss: 1.80239737033844\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "143/300, D Loss: 0.19460761547088623, D Acc: 95.3125, G Loss: 1.7815959453582764\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "144/300, D Loss: 0.21056867018342018, D Acc: 92.1875, G Loss: 1.9397149085998535\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "145/300, D Loss: 0.22369790822267532, D Acc: 90.625, G Loss: 1.8752473592758179\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "146/300, D Loss: 0.29672010242938995, D Acc: 89.0625, G Loss: 1.8533179759979248\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "147/300, D Loss: 0.2806248292326927, D Acc: 89.0625, G Loss: 1.8074254989624023\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "148/300, D Loss: 0.29445700719952583, D Acc: 85.9375, G Loss: 1.7151232957839966\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "149/300, D Loss: 0.27176931500434875, D Acc: 84.375, G Loss: 1.9230495691299438\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "150/300, D Loss: 0.2757277339696884, D Acc: 90.625, G Loss: 1.9598848819732666\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "151/300, D Loss: 0.2792461961507797, D Acc: 92.1875, G Loss: 2.0053300857543945\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "152/300, D Loss: 0.1753387711942196, D Acc: 95.3125, G Loss: 2.0994515419006348\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "153/300, D Loss: 0.1673980988562107, D Acc: 96.875, G Loss: 2.02325439453125\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "154/300, D Loss: 0.1561688855290413, D Acc: 98.4375, G Loss: 2.0772385597229004\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "155/300, D Loss: 0.17350801080465317, D Acc: 93.75, G Loss: 2.1417360305786133\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "156/300, D Loss: 0.23152988404035568, D Acc: 95.3125, G Loss: 1.841140866279602\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "157/300, D Loss: 0.18092487752437592, D Acc: 95.3125, G Loss: 1.599220871925354\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "158/300, D Loss: 0.2383255586028099, D Acc: 93.75, G Loss: 1.7467195987701416\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "159/300, D Loss: 0.1406019888818264, D Acc: 100.0, G Loss: 1.8533927202224731\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "160/300, D Loss: 0.18689141422510147, D Acc: 96.875, G Loss: 2.0073506832122803\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "161/300, D Loss: 0.0981142926029861, D Acc: 100.0, G Loss: 1.9883843660354614\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "162/300, D Loss: 0.1364746429026127, D Acc: 96.875, G Loss: 2.4193758964538574\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "163/300, D Loss: 0.16814325004816055, D Acc: 98.4375, G Loss: 2.205535888671875\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "164/300, D Loss: 0.1629633978009224, D Acc: 96.875, G Loss: 2.37841796875\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "165/300, D Loss: 0.16466615349054337, D Acc: 96.875, G Loss: 2.175661325454712\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "166/300, D Loss: 0.136399757117033, D Acc: 100.0, G Loss: 2.0804972648620605\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "167/300, D Loss: 0.14822496473789215, D Acc: 96.875, G Loss: 2.0630173683166504\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "168/300, D Loss: 0.1645641103386879, D Acc: 98.4375, G Loss: 2.095796823501587\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "169/300, D Loss: 0.20652320981025696, D Acc: 96.875, G Loss: 2.135571002960205\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "170/300, D Loss: 0.14504285342991352, D Acc: 95.3125, G Loss: 2.062851667404175\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "171/300, D Loss: 0.11500680446624756, D Acc: 98.4375, G Loss: 1.9524848461151123\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "172/300, D Loss: 0.09751185681670904, D Acc: 100.0, G Loss: 2.183135986328125\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "173/300, D Loss: 0.14750852435827255, D Acc: 95.3125, G Loss: 2.144869327545166\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "174/300, D Loss: 0.11507058143615723, D Acc: 96.875, G Loss: 2.176222324371338\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "175/300, D Loss: 0.12718679755926132, D Acc: 98.4375, G Loss: 2.316359519958496\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "176/300, D Loss: 0.19064297527074814, D Acc: 92.1875, G Loss: 2.307331085205078\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "177/300, D Loss: 0.12622125633060932, D Acc: 98.4375, G Loss: 2.1175382137298584\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "178/300, D Loss: 0.2500210553407669, D Acc: 95.3125, G Loss: 2.235337257385254\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "179/300, D Loss: 0.10193783789873123, D Acc: 100.0, G Loss: 2.0671825408935547\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "180/300, D Loss: 0.19501443207263947, D Acc: 95.3125, G Loss: 2.16536021232605\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "181/300, D Loss: 0.11417140811681747, D Acc: 98.4375, G Loss: 2.1025493144989014\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "182/300, D Loss: 0.11404505744576454, D Acc: 100.0, G Loss: 2.2366127967834473\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "183/300, D Loss: 0.13412612676620483, D Acc: 98.4375, G Loss: 2.147853374481201\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "184/300, D Loss: 0.12535100802779198, D Acc: 98.4375, G Loss: 2.2322371006011963\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "185/300, D Loss: 0.18377895653247833, D Acc: 96.875, G Loss: 2.0323984622955322\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "186/300, D Loss: 0.1738053783774376, D Acc: 95.3125, G Loss: 2.062194347381592\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "187/300, D Loss: 0.15333957970142365, D Acc: 98.4375, G Loss: 2.068091869354248\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "188/300, D Loss: 0.1220100037753582, D Acc: 100.0, G Loss: 2.1160287857055664\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "189/300, D Loss: 0.12661994993686676, D Acc: 98.4375, G Loss: 2.214470624923706\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "190/300, D Loss: 0.1620260886847973, D Acc: 96.875, G Loss: 2.1605308055877686\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "191/300, D Loss: 0.1121453121304512, D Acc: 98.4375, G Loss: 2.322524070739746\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "192/300, D Loss: 0.09143450669944286, D Acc: 98.4375, G Loss: 2.4870476722717285\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "193/300, D Loss: 0.10443236492574215, D Acc: 100.0, G Loss: 2.505610466003418\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "194/300, D Loss: 0.09043491631746292, D Acc: 98.4375, G Loss: 2.486992835998535\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "195/300, D Loss: 0.17646117135882378, D Acc: 96.875, G Loss: 2.5461738109588623\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "196/300, D Loss: 0.09530419483780861, D Acc: 98.4375, G Loss: 2.5243492126464844\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "197/300, D Loss: 0.06640183413401246, D Acc: 100.0, G Loss: 2.5286412239074707\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "198/300, D Loss: 0.06629220908507705, D Acc: 100.0, G Loss: 2.782034158706665\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "199/300, D Loss: 0.04242690757382661, D Acc: 100.0, G Loss: 2.6822381019592285\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "200/300, D Loss: 0.0699538104236126, D Acc: 98.4375, G Loss: 2.651495933532715\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "201/300, D Loss: 0.044953168369829655, D Acc: 100.0, G Loss: 2.919005870819092\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "202/300, D Loss: 0.09408693760633469, D Acc: 98.4375, G Loss: 3.240490198135376\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "203/300, D Loss: 0.03797912271693349, D Acc: 100.0, G Loss: 3.256185531616211\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "204/300, D Loss: 0.04288714937865734, D Acc: 100.0, G Loss: 3.435335636138916\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "205/300, D Loss: 0.05377247929573059, D Acc: 100.0, G Loss: 3.0429587364196777\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "206/300, D Loss: 0.03992712218314409, D Acc: 100.0, G Loss: 3.3571085929870605\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "207/300, D Loss: 0.053868355229496956, D Acc: 98.4375, G Loss: 2.875342845916748\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "208/300, D Loss: 0.111386027187109, D Acc: 95.3125, G Loss: 3.0408549308776855\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "209/300, D Loss: 0.04531731270253658, D Acc: 100.0, G Loss: 3.185274839401245\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "210/300, D Loss: 0.046159394551068544, D Acc: 100.0, G Loss: 2.9654269218444824\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "211/300, D Loss: 0.0716637959703803, D Acc: 100.0, G Loss: 2.94179368019104\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "212/300, D Loss: 0.04440179554512724, D Acc: 100.0, G Loss: 2.944498300552368\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "213/300, D Loss: 0.07131448108702898, D Acc: 98.4375, G Loss: 3.2117490768432617\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "214/300, D Loss: 0.05366387323010713, D Acc: 100.0, G Loss: 2.991417646408081\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "215/300, D Loss: 0.03927116992417723, D Acc: 100.0, G Loss: 3.088122844696045\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "216/300, D Loss: 0.1058822013437748, D Acc: 98.4375, G Loss: 3.149442672729492\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "217/300, D Loss: 0.06660812348127365, D Acc: 98.4375, G Loss: 3.048205852508545\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "218/300, D Loss: 0.055030206218361855, D Acc: 98.4375, G Loss: 3.093635082244873\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "219/300, D Loss: 0.0975535400211811, D Acc: 96.875, G Loss: 3.3329832553863525\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "220/300, D Loss: 0.10144821926951408, D Acc: 98.4375, G Loss: 2.596916675567627\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "221/300, D Loss: 0.06924358522519469, D Acc: 98.4375, G Loss: 2.7865257263183594\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "222/300, D Loss: 0.09905223548412323, D Acc: 96.875, G Loss: 2.684269905090332\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "223/300, D Loss: 0.06561196595430374, D Acc: 98.4375, G Loss: 2.9486687183380127\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "224/300, D Loss: 0.09511143679264933, D Acc: 95.3125, G Loss: 2.885502338409424\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "225/300, D Loss: 0.08267806726507843, D Acc: 98.4375, G Loss: 2.7808680534362793\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "226/300, D Loss: 0.03643560968339443, D Acc: 100.0, G Loss: 2.9446401596069336\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "227/300, D Loss: 0.0844740653410554, D Acc: 98.4375, G Loss: 3.1309380531311035\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "228/300, D Loss: 0.04926262982189655, D Acc: 100.0, G Loss: 2.972752094268799\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "229/300, D Loss: 0.07012812048196793, D Acc: 98.4375, G Loss: 3.347928047180176\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "230/300, D Loss: 0.11237027123570442, D Acc: 96.875, G Loss: 2.909656524658203\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "231/300, D Loss: 0.13698305189609528, D Acc: 96.875, G Loss: 2.699315071105957\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "232/300, D Loss: 0.12111203745007515, D Acc: 95.3125, G Loss: 2.8970909118652344\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "233/300, D Loss: 0.11672134324908257, D Acc: 98.4375, G Loss: 2.3136239051818848\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "234/300, D Loss: 0.08122339594410732, D Acc: 100.0, G Loss: 2.558465003967285\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "235/300, D Loss: 0.12920632539317012, D Acc: 98.4375, G Loss: 2.281209945678711\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "236/300, D Loss: 0.09118140488862991, D Acc: 100.0, G Loss: 2.997206449508667\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "237/300, D Loss: 0.08114996139192954, D Acc: 98.4375, G Loss: 2.735642194747925\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "238/300, D Loss: 0.072606286033988, D Acc: 98.4375, G Loss: 2.7752552032470703\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "239/300, D Loss: 0.09167070686817169, D Acc: 96.875, G Loss: 3.0686168670654297\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "240/300, D Loss: 0.07134476769715548, D Acc: 100.0, G Loss: 3.468024730682373\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "241/300, D Loss: 0.07747045904397964, D Acc: 98.4375, G Loss: 3.2532694339752197\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "242/300, D Loss: 0.03673297353088856, D Acc: 100.0, G Loss: 3.4468584060668945\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "243/300, D Loss: 0.11873138695955276, D Acc: 96.875, G Loss: 3.277273416519165\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "244/300, D Loss: 0.06029029004275799, D Acc: 98.4375, G Loss: 3.1869781017303467\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "245/300, D Loss: 0.08865742012858391, D Acc: 96.875, G Loss: 2.9992523193359375\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "246/300, D Loss: 0.09023449942469597, D Acc: 96.875, G Loss: 2.986367702484131\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "247/300, D Loss: 0.08620758913457394, D Acc: 96.875, G Loss: 3.095459461212158\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "248/300, D Loss: 0.06279883533716202, D Acc: 100.0, G Loss: 2.7972311973571777\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "249/300, D Loss: 0.08404936641454697, D Acc: 100.0, G Loss: 2.895861864089966\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "250/300, D Loss: 0.12621788680553436, D Acc: 96.875, G Loss: 2.595325469970703\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "251/300, D Loss: 0.09120000340044498, D Acc: 98.4375, G Loss: 2.909557342529297\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "252/300, D Loss: 0.05938391946256161, D Acc: 100.0, G Loss: 3.402888774871826\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "253/300, D Loss: 0.09209506213665009, D Acc: 98.4375, G Loss: 2.9170584678649902\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "254/300, D Loss: 0.04356512147933245, D Acc: 100.0, G Loss: 2.8720998764038086\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "255/300, D Loss: 0.060700676403939724, D Acc: 100.0, G Loss: 2.8214375972747803\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "256/300, D Loss: 0.05910901166498661, D Acc: 100.0, G Loss: 3.2667150497436523\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "257/300, D Loss: 0.06897187978029251, D Acc: 100.0, G Loss: 3.138909339904785\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "258/300, D Loss: 0.12166017293930054, D Acc: 98.4375, G Loss: 2.772937536239624\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "259/300, D Loss: 0.07156864181160927, D Acc: 98.4375, G Loss: 2.7503952980041504\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "260/300, D Loss: 0.09199424833059311, D Acc: 98.4375, G Loss: 2.9724416732788086\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "261/300, D Loss: 0.10135084390640259, D Acc: 96.875, G Loss: 2.598799467086792\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "262/300, D Loss: 0.07522915303707123, D Acc: 98.4375, G Loss: 2.093313694000244\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "263/300, D Loss: 0.07385104894638062, D Acc: 100.0, G Loss: 2.1237945556640625\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "264/300, D Loss: 0.10291708260774612, D Acc: 98.4375, G Loss: 2.4760828018188477\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "265/300, D Loss: 0.08381102979183197, D Acc: 98.4375, G Loss: 2.632981061935425\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "266/300, D Loss: 0.08466350706294179, D Acc: 100.0, G Loss: 2.8754513263702393\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "267/300, D Loss: 0.09173007495701313, D Acc: 98.4375, G Loss: 2.8637161254882812\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "268/300, D Loss: 0.09094575047492981, D Acc: 100.0, G Loss: 2.8268990516662598\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "269/300, D Loss: 0.05047473171725869, D Acc: 100.0, G Loss: 3.1517653465270996\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "270/300, D Loss: 0.10626734420657158, D Acc: 98.4375, G Loss: 3.100325107574463\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "271/300, D Loss: 0.129789337515831, D Acc: 96.875, G Loss: 3.053834915161133\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "272/300, D Loss: 0.1212640106678009, D Acc: 96.875, G Loss: 2.935742139816284\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "273/300, D Loss: 0.05991437565535307, D Acc: 100.0, G Loss: 2.3941521644592285\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "274/300, D Loss: 0.09158343449234962, D Acc: 100.0, G Loss: 2.512086868286133\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "275/300, D Loss: 0.09403777762781829, D Acc: 96.875, G Loss: 2.616448402404785\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "276/300, D Loss: 0.09712722897529602, D Acc: 98.4375, G Loss: 2.623222827911377\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "277/300, D Loss: 0.08314652694389224, D Acc: 98.4375, G Loss: 2.672389507293701\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "278/300, D Loss: 0.0730285756289959, D Acc: 100.0, G Loss: 2.9106483459472656\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "279/300, D Loss: 0.06102164555341005, D Acc: 100.0, G Loss: 3.104170799255371\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "280/300, D Loss: 0.13573085516691208, D Acc: 93.75, G Loss: 2.7839584350585938\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "281/300, D Loss: 0.08254620246589184, D Acc: 100.0, G Loss: 2.6816916465759277\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "282/300, D Loss: 0.133927620947361, D Acc: 95.3125, G Loss: 2.3804380893707275\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "283/300, D Loss: 0.12725892290472984, D Acc: 95.3125, G Loss: 2.335847854614258\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "284/300, D Loss: 0.11252023233100772, D Acc: 95.3125, G Loss: 2.2660369873046875\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "285/300, D Loss: 0.14484552294015884, D Acc: 95.3125, G Loss: 2.3061046600341797\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "286/300, D Loss: 0.09046446159482002, D Acc: 100.0, G Loss: 2.4909965991973877\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "287/300, D Loss: 0.1361980438232422, D Acc: 96.875, G Loss: 2.3583717346191406\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "288/300, D Loss: 0.09956813976168633, D Acc: 100.0, G Loss: 2.511547803878784\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "289/300, D Loss: 0.09169074706733227, D Acc: 98.4375, G Loss: 3.2241506576538086\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "290/300, D Loss: 0.13329065591096878, D Acc: 96.875, G Loss: 2.793578624725342\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "291/300, D Loss: 0.12853964418172836, D Acc: 96.875, G Loss: 2.9261326789855957\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "292/300, D Loss: 0.1694248467683792, D Acc: 93.75, G Loss: 2.7070882320404053\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "293/300, D Loss: 0.10745272226631641, D Acc: 100.0, G Loss: 2.4078750610351562\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "294/300, D Loss: 0.10682367905974388, D Acc: 100.0, G Loss: 2.118732452392578\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "295/300, D Loss: 0.14066393300890923, D Acc: 98.4375, G Loss: 2.1369030475616455\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "296/300, D Loss: 0.1324903666973114, D Acc: 96.875, G Loss: 2.177077293395996\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "297/300, D Loss: 0.09025655128061771, D Acc: 100.0, G Loss: 2.341926097869873\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "298/300, D Loss: 0.07760701514780521, D Acc: 100.0, G Loss: 2.539675235748291\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "299/300, D Loss: 0.1183776892721653, D Acc: 96.875, G Loss: 2.70790433883667\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "300/300, D Loss: 0.1164211556315422, D Acc: 98.4375, G Loss: 2.9345836639404297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MboVMJOSDD2p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}